{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detction from documents using n-gram profiles\n",
    "\n",
    "This notebook is an attempt at building an n-gram profile based language detector inspired by [N-gram-based text categorization Cavnar, Trenkle (1994)](https://sdmines.sdsmt.edu/upload/directory/materials/12247_20070403135416.pdf).\n",
    "\n",
    "\n",
    "\n",
    "#### BibTex entry\n",
    "```bibtex\n",
    "@inproceedings{Cavnar1994NgrambasedTC,\n",
    "  title={N-gram-based text categorization},\n",
    "  author={William B. Cavnar and John M. Trenkle},\n",
    "  year={1994},\n",
    "  url={https://api.semanticscholar.org/CorpusID:170740}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core concept\n",
    "\n",
    "According to the Zipf's Law, the most dominant words in a language are lesser in frequency than their more frequent yet less dominant counterparts. N-gram profiles are built on the idea of the ranking of the most prominent n-grams in a language.\n",
    "\n",
    "Let's assume that we have a corpus $C$ of $N$ languages. For each language $L$ in the $C$, we can then create the ranking of the most common n-grams, which will act as the n-gram profile, $R_l$ for $l$. Once the profiles for all languages have been computed, we can infer on a held out corpus, containing $S$ sentences. For each sentence $s$ in the corpus, we first create the n-gram profile of $s$, $R_s$. Then, we measure the distance in the rankings of the n-grams in $R_s$ against the n-gram profiles of all the languages. In the end, the language which will have the least distance is selected as the predicted result. For our prediction target $y_l$, \n",
    "\n",
    "$$\n",
    "y_l = min(R_{s_i} - [R_{L_1} , R_{L_2}, ... , R_{N}])\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using this small corpus from Kaggle titled [Language Detection](https://www.kaggle.com/code/basilb2s/language-detection-using-nlp). It contains 17 languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'rai', 'isLiveDataset', 'examples'}\n",
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(Language Detection)] Property \"http://mlcommons.org/croissant/citeAs\" is recommended, but does not exist.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_URL = \"https://www.kaggle.com/datasets/basilb2s/language-detection/croissant/download\"\n",
    "\n",
    "def get_croissant_dataset(dataset_url: str = DATASET_URL) -> pd.DataFrame:\n",
    "    # Fetch the Croissant JSON-LD\n",
    "    croissant_dataset = mlc.Dataset(dataset_url)\n",
    "\n",
    "    # Check what record sets are in the dataset\n",
    "    record_sets = croissant_dataset.metadata.record_sets\n",
    "\n",
    "    # Fetch the records and put them in a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        croissant_dataset.records(record_set=record_sets[0].uuid))\n",
    "    \n",
    "    # Rename the columns\n",
    "    df.rename(columns={\"Language+Detection.csv/Text\": \"text\",\n",
    "              \"Language+Detection.csv/Language\": \"language\"}, inplace=True)\n",
    "    \n",
    "    # convert the binary strings to utf-8\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "    df[\"language\"] = df[\"language\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = get_croissant_dataset()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language to index dictionary\n",
    "\n",
    "I'm assigning an integer id to each of the unique target languages in the dataset, which can then be used as index while creating language specific arrays later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'Malayalam', 'Hindi', 'Tamil', 'Portugeese', 'French',\n",
       "       'Dutch', 'Spanish', 'Greek', 'Russian', 'Danish', 'Italian',\n",
       "       'Turkish', 'Sweedish', 'Arabic', 'German', 'Kannada'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_languages = df[\"language\"].unique()\n",
    "unique_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swedish and Portuguese are misspelled here. I am going to fix it before proceeding any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'Malayalam', 'Hindi', 'Tamil', 'Portuguese', 'French',\n",
       "       'Dutch', 'Spanish', 'Greek', 'Russian', 'Danish', 'Italian',\n",
       "       'Turkish', 'Swedish', 'Arabic', 'German', 'Kannada'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_spelling(lang: str) -> str:\n",
    "    \"\"\"Fix the spelling of the language name\"\"\"\n",
    "    spelling = {\n",
    "        \"Portugeese\": \"Portuguese\",\n",
    "        \"Sweedish\": \"Swedish\",\n",
    "    }\n",
    "    return spelling.get(lang, lang)\n",
    "\n",
    "\n",
    "df[\"language\"] = df[\"language\"].apply(fix_spelling)\n",
    "unique_languages = df[\"language\"].unique()\n",
    "unique_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to apply the following pre-proessing steps:\n",
    "\n",
    "1. Tokenization\n",
    "2. Stop word removal\n",
    "3. Punctuation removal\n",
    "4. Number removal\n",
    "\n",
    "Now would also be a good time to check for which languages in the corpus, there's no stopwords list. This is important since the whole approach relies on finding the dominant n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Malayalam', 'Hindi', 'Tamil', 'Kannada']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sw_missing_languages(languages: list[str]):\n",
    "    \"\"\"Find the languages that are missing stopwords\"\"\"\n",
    "    missing = []\n",
    "    for lang in languages:\n",
    "        try:\n",
    "            _ = stopwords.words(lang.lower())\n",
    "        except Exception:\n",
    "            missing.append(lang)\n",
    "        \n",
    "            \n",
    "    return missing\n",
    "\n",
    "\n",
    "missing_languages = find_sw_missing_languages(unique_languages.tolist())\n",
    "missing_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to exclude the data for these languages from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to write a combined function to preprocess the corpus\n",
    "\n",
    "import string\n",
    "\n",
    "def lower_case(text: str, language: str) -> str:\n",
    "    \"\"\"Lower case the text\"\"\"\n",
    "    return text.lower(), language.lower()\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str, language: str) -> list[str]:\n",
    "    \"\"\"Remove stopwords from the text\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    return [word for word in tokens if word not in stopwords.words(language)]\n",
    "\n",
    "\n",
    "def remove_punctuation(text: str) -> list[str]:\n",
    "    \"\"\"Remove punctuation from the text\"\"\"\n",
    "    return [word for word in text if word not in string.punctuation]\n",
    "\n",
    "def remove_numbers(text: str) -> list[str]:\n",
    "    \"\"\"Remove numbers from the text\"\"\"\n",
    "    return [word for word in text if not word.isdigit()]\n",
    "\n",
    "def remove_special_characters(text: str) -> list[str]:\n",
    "    \"\"\"Remove special characters from the text\"\"\"\n",
    "    return [word for word in text if word.isalnum()]\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame):\n",
    "    \"\"\"Preprocess the data\"\"\"\n",
    "    # remove languages missing stopwords\n",
    "    missing_languages = find_sw_missing_languages(df[\"language\"].unique())\n",
    "    df = df[~df[\"language\"].isin(missing_languages)]\n",
    "    assert find_sw_missing_languages(df[\"language\"].unique()) == []\n",
    "    \n",
    "    # fix spelling\n",
    "    df[\"language\"] = df[\"language\"].apply(fix_spelling)\n",
    "    \n",
    "    # lower case, also tokenize\n",
    "    df[\"text\"], df[\"language\"] = zip(*df.apply(lambda x: lower_case(x[\"text\"], x[\"language\"]), axis=1))\n",
    "    \n",
    "    # remove stopwords\n",
    "    df[\"text\"] = df.apply(lambda x: remove_stopwords(x[\"text\"], x[\"language\"]), axis=1)\n",
    "    \n",
    "    # remove punctuation\n",
    "    df[\"text\"] = df.apply(lambda x: remove_punctuation(x[\"text\"]), axis=1)\n",
    "    \n",
    "    # remove numbers\n",
    "    df[\"text\"] = df.apply(lambda x: remove_numbers(x[\"text\"]), axis=1)\n",
    "\n",
    "    \n",
    "    # mapping language to index\n",
    "    unique_languages = df[\"language\"].unique()\n",
    "    language_to_index = {language: index for index, language in enumerate(unique_languages)}\n",
    "    return df, language_to_index\n",
    "\n",
    "# ==============================\n",
    "# loading df again\n",
    "df = get_croissant_dataset()\n",
    "df, language_to_index = preprocess(df)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nature, broadest, sense, natural, physical, m...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[``, nature, '', refer, phenomena, physical, w...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[study, nature, large, part, science]</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[although, humans, part, nature, human, activi...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[word, nature, borrowed, old, french, nature, ...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0  [nature, broadest, sense, natural, physical, m...  english\n",
       "1  [``, nature, '', refer, phenomena, physical, w...  english\n",
       "2              [study, nature, large, part, science]  english\n",
       "3  [although, humans, part, nature, human, activi...  english\n",
       "4  [word, nature, borrowed, old, french, nature, ...  english"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts, languages = df[\"text\"], df[\"language\"]\n",
    "train_texts, test_texts, train_languages, test_languages = train_test_split(texts, languages, test_size=0.2, random_state=42)\n",
    "\n",
    "assert len(train_texts) == len(train_languages)\n",
    "assert len(test_texts) == len(test_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Language:\n",
    "    id: int\n",
    "    name: str\n",
    "    profile: dict    \n",
    "    def __eq__(self, other: \"Language\") -> bool:\n",
    "        # two languages are equal if their profiles are the same\n",
    "        return np.array_equal(self.profile, other.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NGrams:\n",
    "    n: int\n",
    "    language: str\n",
    "    grams: list[str]\n",
    "    \n",
    "    def __eq__(self, other: \"NGrams\") -> bool:\n",
    "        # two n-grams are equal if their n and the language are the same\n",
    "        return self.n == other.n and self.language == other.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class NGramProfileClassifier:\n",
    "    def __init__(self, n: int, mapping: dict[str, int], profile_size: int = 25):\n",
    "        self.n = n\n",
    "        self.mapping = mapping\n",
    "        self.profile_size = profile_size\n",
    "        \n",
    "        # a dictionary of languages and their n-gram profiles\n",
    "        self.languages = {}\n",
    "        self.n_grams = {}\n",
    "        self.__populate()\n",
    "        \n",
    "        # number of languages\n",
    "        self.n_languages = len(self.mapping)\n",
    "        \n",
    "        \n",
    "    def __populate(self):\n",
    "        for language, index in self.mapping.items():\n",
    "            self.languages[language] = Language(index, language, {})\n",
    "            self.n_grams[language] = NGrams(n=self.n, language=language, grams=[])\n",
    "            \n",
    "            \n",
    "    def __process_single(self, text_tokens: str):\n",
    "        # create the n-grams\n",
    "        n_grams = ngrams(text_tokens, self.n)\n",
    "        n_grams = list(n_grams)\n",
    "        return n_grams\n",
    "            \n",
    "    \n",
    "    def __process_texts(self, text_tokens: list[list[str]], languages: list[str]):\n",
    "        for text_tokens, language in tqdm(zip(text_tokens, languages), total=len(text_tokens), desc=\"processing texts\"):\n",
    "            n_grams = self.__process_single(text_tokens)\n",
    "                \n",
    "            # add the n-grams to the n-grams list\n",
    "            self.n_grams[language].grams.extend(n_grams)  \n",
    "            \n",
    "            \n",
    "    def __get_least_common_n_grams(self, n_grams: list[str], n: int):\n",
    "        counts = Counter(n_grams)\n",
    "        least_common = sorted(counts.items(), key=lambda x: x[1])[:n]\n",
    "        return least_common\n",
    "    \n",
    "    \n",
    "    def get_profile(self, n_grams: list[str], n: int):\n",
    "        counts = Counter(n_grams)\n",
    "        least_commons = self.__get_least_common_n_grams(counts, n)\n",
    "        profile = {k[0]: v for k, v in least_commons}\n",
    "        return profile\n",
    "                \n",
    "                \n",
    "    def __build_language_profiles(self):\n",
    "        for language, n_grams in self.n_grams.items():\n",
    "            profile = self.get_profile(n_grams.grams, self.profile_size)\n",
    "            self.languages[language].profile = dict(profile)\n",
    "            \n",
    "    \n",
    "    def fit(self, text_tokens: list[list[str]], languages: list[str]):\n",
    "        assert len(text_tokens) == len(languages)\n",
    "        \n",
    "        # first create the n-grams for each text and language\n",
    "        self.__process_texts(text_tokens, languages)\n",
    "        \n",
    "        # create the profile for the language\n",
    "        self.__build_language_profiles()\n",
    "        \n",
    "    \n",
    "    def __distance(self, text_profile: dict, language_name: str):\n",
    "        language_profile = self.languages[language_name].profile\n",
    "        # find the common keys\n",
    "        common_keys = set(text_profile.keys()) & set(language_profile.keys())\n",
    "                \n",
    "        distance = 0.0\n",
    "        for ck in common_keys:\n",
    "            distance += abs(text_profile[ck] - language_profile[ck])\n",
    "        return distance\n",
    "    \n",
    "    def get_distance(self, text_profile: dict):\n",
    "        distances  = []\n",
    "        language_names = [lang for lang in self.languages.keys()]\n",
    "        \n",
    "        for language_name in language_names:\n",
    "            distances.append(self.__distance(text_profile, language_name))\n",
    "            \n",
    "        return distances\n",
    "        \n",
    "    \n",
    "    def __get_language_name(self, index: int):\n",
    "        return [lang for lang, idx in self.mapping.items() if idx == index][0]\n",
    "        \n",
    "    \n",
    "    def predict_single(self, text_tokens: list[str]) -> str:\n",
    "        \"\"\"Predict the language name in lowercase\"\"\"\n",
    "        \n",
    "        # preprocess the text and get the profile\n",
    "        text_profile = self.get_profile(text_tokens, self.profile_size)\n",
    "        \n",
    "        # get the distances\n",
    "        distances = self.get_distance(text_profile)\n",
    "        distances = np.array(distances)\n",
    "        \n",
    "        prediction = np.argmin(distances)\n",
    "        prediction = self.__get_language_name(prediction)\n",
    "        return prediction\n",
    "    \n",
    "    def predict(self, text_tokens: list[list[str]]) -> list[str]:\n",
    "        \"\"\"Predict the language of the texts\"\"\"\n",
    "        predictions = [self.predict_single(text_tokens) for text_tokens in text_tokens]\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(clf: NGramProfileClassifier, test_dataset: list[list[str]]) -> list[str]:\n",
    "    \"\"\"Infer the language of the text\"\"\"\n",
    "    return clf.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Since this is a classification task, I am using the usual accuracy, precision, recall and f1-score as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "def evaluate(predictions: list[str], labels: list[str]) -> tuple[float, float, float, float]:\n",
    "    \"\"\"Evaluate the predictions\"\"\"\n",
    "    accuracy = accuracy_score(predictions, labels)\n",
    "    precision = precision_score(predictions, labels, average='macro')\n",
    "    recall = recall_score(predictions, labels, average='macro')\n",
    "    f1 = f1_score(predictions, labels, average='macro')\n",
    "    \n",
    "    # also print the classification report\n",
    "    print(classification_report(predictions, labels))\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eca9fe8e764e5595835dde8716fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing texts:   0%|          | 0/5941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for unigrams\n",
    "unigram_clf = NGramProfileClassifier(n=1, mapping=language_to_index)\n",
    "unigram_clf.fit(train_texts, train_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      arabic       0.00      0.00      0.00         0\n",
      "      danish       0.00      0.00      0.00         0\n",
      "       dutch       0.00      0.00      0.00         0\n",
      "     english       1.00      0.19      0.32      1486\n",
      "      french       0.00      0.00      0.00         0\n",
      "      german       0.00      0.00      0.00         0\n",
      "       greek       0.00      0.00      0.00         0\n",
      "     italian       0.00      0.00      0.00         0\n",
      "     russian       0.00      0.00      0.00         0\n",
      "     spanish       0.00      0.00      0.00         0\n",
      "     turkish       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19      1486\n",
      "   macro avg       0.09      0.02      0.03      1486\n",
      "weighted avg       1.00      0.19      0.32      1486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "unigram_predictions = unigram_clf.predict(test_texts)\n",
    "unigram_scores = evaluate(unigram_predictions, test_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597515cdbb5c4112a0cca955bff9a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing texts:   0%|          | 0/5941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for bigrams\n",
    "bigram_clf = NGramProfileClassifier(n=2, mapping=language_to_index)\n",
    "bigram_clf.fit(train_texts, train_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      arabic       0.00      0.00      0.00         0\n",
      "      danish       0.00      0.00      0.00         0\n",
      "       dutch       0.00      0.00      0.00         0\n",
      "     english       1.00      0.19      0.32      1486\n",
      "      french       0.00      0.00      0.00         0\n",
      "      german       0.00      0.00      0.00         0\n",
      "       greek       0.00      0.00      0.00         0\n",
      "     italian       0.00      0.00      0.00         0\n",
      "     russian       0.00      0.00      0.00         0\n",
      "     spanish       0.00      0.00      0.00         0\n",
      "     turkish       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19      1486\n",
      "   macro avg       0.09      0.02      0.03      1486\n",
      "weighted avg       1.00      0.19      0.32      1486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "bigram_predictions = bigram_clf.predict(test_texts)\n",
    "bigram_scores = evaluate(bigram_predictions, test_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee7b9fa91d945e4b79a65c322c6a654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing texts:   0%|          | 0/5941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for trigrams\n",
    "trigram_clf = NGramProfileClassifier(n=3, mapping=language_to_index)\n",
    "trigram_clf.fit(train_texts, train_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      arabic       0.00      0.00      0.00         0\n",
      "      danish       0.00      0.00      0.00         0\n",
      "       dutch       0.00      0.00      0.00         0\n",
      "     english       1.00      0.19      0.32      1486\n",
      "      french       0.00      0.00      0.00         0\n",
      "      german       0.00      0.00      0.00         0\n",
      "       greek       0.00      0.00      0.00         0\n",
      "     italian       0.00      0.00      0.00         0\n",
      "     russian       0.00      0.00      0.00         0\n",
      "     spanish       0.00      0.00      0.00         0\n",
      "     turkish       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19      1486\n",
      "   macro avg       0.09      0.02      0.03      1486\n",
      "weighted avg       1.00      0.19      0.32      1486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shawon/Codes/oss/language-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "trigram_predictions = trigram_clf.predict(test_texts)\n",
    "trigram_scores = evaluate(trigram_predictions, test_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'origins': 1,\n",
       " 'origin': 1,\n",
       " 'pleasant': 1,\n",
       " 'tasting': 1,\n",
       " '9th': 1,\n",
       " 'millennium': 1,\n",
       " 'bce': 1,\n",
       " 'gardens': 1,\n",
       " 'aesthetic': 1,\n",
       " 'ornamentation': 1,\n",
       " 'breeding': 1,\n",
       " 'thermal': 1,\n",
       " 'meteorite': 1,\n",
       " 'collision': 1,\n",
       " 'probably': 1,\n",
       " 'triggered': 1,\n",
       " 'non-avian': 1,\n",
       " 'dinosaurs': 1,\n",
       " 'reptiles': 1,\n",
       " 'spared': 1,\n",
       " 'mammals': 1,\n",
       " 'complain': 1,\n",
       " 'somehow': 1,\n",
       " 'parliament': 1,\n",
       " 'oviedo': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_clf.languages[\"english\"].profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
